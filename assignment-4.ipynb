{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6cffd3",
   "metadata": {},
   "source": [
    "# Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc347c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import debugger\n",
    "import re\n",
    "\n",
    "# selenium\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "# Beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#import warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# add time\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d39b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2398f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank of the videos\n",
    "Rank=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e1b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name of the videos\n",
    "Name=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c494027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Artist of the videos\n",
    "Artist=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a78a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Upload_Date of the videos\n",
    "Date=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706619ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Views of the videos\n",
    "Views=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00f37a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Name),len(Artist),len(Date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3e2271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views(in_billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[24]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[29]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"[36]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[37]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[38]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[41]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[48]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.                              \"Gangnam Style\"[24]   \n",
       "10  11.   \"Masha and the Bear – Recipe for Disaster\"[29]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                                     \"Axel F\"[36]   \n",
       "18  18.                          \"Thinking Out Loud\"[37]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[38]   \n",
       "20  21.                                 \"Dark Horse\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                             \"Girls Like You\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.          \"Humpty the train on a fruits ride\"[48]   \n",
       "\n",
       "                                           Artist        Upload_Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                                      Ed Sheeran   January 30, 2017   \n",
       "4                                     Wiz Khalifa      April 6, 2015   \n",
       "5                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                                     Mark Ronson  November 19, 2014   \n",
       "8                                     Miroshka TV  February 27, 2018   \n",
       "9                                             Psy      July 15, 2012   \n",
       "10                                     Get Movies   January 31, 2012   \n",
       "11                     Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Katy Perry  September 5, 2013   \n",
       "15                                    OneRepublic       May 31, 2013   \n",
       "16                                  Justin Bieber   October 22, 2015   \n",
       "17                                     Crazy Frog      June 16, 2009   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                     Katy Perry  February 20, 2014   \n",
       "21                                    Alan Walker   December 3, 2015   \n",
       "22                                       Maroon 5       May 31, 2018   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                               Enrique Iglesias     April 11, 2014   \n",
       "25                                    Major Lazer     March 22, 2015   \n",
       "26                                     Ed Sheeran   November 9, 2017   \n",
       "27                                        Shakira       June 4, 2010   \n",
       "28                                   Taylor Swift    August 18, 2014   \n",
       "29  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "\n",
       "   Views(in_billion)  \n",
       "0              11.30  \n",
       "1               7.97  \n",
       "2               6.45  \n",
       "3               5.80  \n",
       "4               5.63  \n",
       "5               5.60  \n",
       "6               4.87  \n",
       "7               4.68  \n",
       "8               4.61  \n",
       "9               4.54  \n",
       "10              4.51  \n",
       "11              4.34  \n",
       "12              4.06  \n",
       "13              3.75  \n",
       "14              3.65  \n",
       "15              3.64  \n",
       "16              3.58  \n",
       "17              3.50  \n",
       "18              3.49  \n",
       "19              3.36  \n",
       "20              3.34  \n",
       "21              3.34  \n",
       "22              3.33  \n",
       "23              3.29  \n",
       "24              3.26  \n",
       "25              3.26  \n",
       "26              3.25  \n",
       "27              3.24  \n",
       "28              3.20  \n",
       "29              3.15  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "       # creating DataFrame for scraped data\n",
    "Wiki = pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Upload_Date':Date,'Views(in_billion)':Views})\n",
    "Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22845b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985d090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b7ab4c",
   "metadata": {},
   "source": [
    "# Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dbdfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the webdriver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of bcci.tv url\n",
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8409f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element(By.XPATH,\"//*[@id='navigation']/ul[1]/li[2]/a\")\n",
    "driver.get(btn.get_attribute(\"href\"))\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57c11db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = driver.find_elements(By.XPATH,\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "#to remove extra data other than output we required\n",
    "Match_title = []\n",
    "for i in match:\n",
    "    Match_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a360736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the tag having Series\n",
    "series = driver.find_elements(By.XPATH,\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "#to remove extra data other than output we required\n",
    "Series = []\n",
    "for i in series:\n",
    "    Series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5edc7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Place\n",
    "place = driver.find_elements(By.XPATH,\"//p[@class='fixture__additional-info']//span\")\n",
    "#to remove extra data other than output we required\n",
    "Place = []\n",
    "for i in place:\n",
    "    Place.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac35900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Date\n",
    "date =driver.find_elements(By.XPATH,\"//div[@class='fixture__full-date']\")\n",
    "#to remove extra data other than output we required\n",
    "Date = []\n",
    "for i in date:\n",
    "    Date.append(i.text.replace('\\n', ' ').replace(' 14:00 IST', ' 2022').replace(' 15:30 IST', ' 2022').replace(' 17:30 IST', ' 2022'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41700b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Time\n",
    "time = driver.find_elements(By.XPATH,\"//span[@class='fixture__time']\")\n",
    "#to remove extra data other than output we required\n",
    "Time = []\n",
    "for i in time:\n",
    "    Time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcc88596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Match Title, Series, Place, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fictures = pd.DataFrame({})\n",
    "fictures['Match Title']= Match_title\n",
    "fictures['Series'] = Series\n",
    "fictures['Place'] = Place\n",
    "fictures['Date'] = Date\n",
    "fictures['Time'] = Time \n",
    "fictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad214f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecd407c2",
   "metadata": {},
   "source": [
    "# Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52eb8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = (\"https://www.guru99.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61f1a802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Exception Handling button\n",
    "driver.find_element(By.XPATH,'//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1fb5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Name\n",
    "Name=[]\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='post-1953']/div/div/p[1]/strong\"):\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21c7c243",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSelectorException",
     "evalue": "Message: invalid selector: The result of the xpath expression \"//*[@id='post-1953']/div/div/p[1]/text()\" is: [object Text]. It should be an element.\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x002A78B3+2193587]\n\tOrdinal0 [0x00240681+1771137]\n\tOrdinal0 [0x001541A8+803240]\n\tOrdinal0 [0x00156BB4+814004]\n\tOrdinal0 [0x00156A72+813682]\n\tOrdinal0 [0x00156D00+814336]\n\tOrdinal0 [0x001821B5+991669]\n\tOrdinal0 [0x0018273B+993083]\n\tOrdinal0 [0x001AF7C2+1177538]\n\tOrdinal0 [0x0019D7F4+1103860]\n\tOrdinal0 [0x001ADAE2+1170146]\n\tOrdinal0 [0x0019D5C6+1103302]\n\tOrdinal0 [0x001777E0+948192]\n\tOrdinal0 [0x001786E6+952038]\n\tGetHandleVerifier [0x00550CB2+2738370]\n\tGetHandleVerifier [0x005421B8+2678216]\n\tGetHandleVerifier [0x003317AA+512954]\n\tGetHandleVerifier [0x00330856+509030]\n\tOrdinal0 [0x0024743B+1799227]\n\tOrdinal0 [0x0024BB68+1817448]\n\tOrdinal0 [0x0024BC55+1817685]\n\tOrdinal0 [0x00255230+1856048]\n\tBaseThreadInitThunk [0x778CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E37A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77E37A6E+238]\n\t(No symbol) [0x00000000]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3284/598513182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# scraping Description\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mDescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"//*[@id='post-1953']/div/div/p[1]/text()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mDescription\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    436\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mInvalidSelectorException\u001b[0m: Message: invalid selector: The result of the xpath expression \"//*[@id='post-1953']/div/div/p[1]/text()\" is: [object Text]. It should be an element.\n  (Session info: chrome=105.0.5195.102)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x002A78B3+2193587]\n\tOrdinal0 [0x00240681+1771137]\n\tOrdinal0 [0x001541A8+803240]\n\tOrdinal0 [0x00156BB4+814004]\n\tOrdinal0 [0x00156A72+813682]\n\tOrdinal0 [0x00156D00+814336]\n\tOrdinal0 [0x001821B5+991669]\n\tOrdinal0 [0x0018273B+993083]\n\tOrdinal0 [0x001AF7C2+1177538]\n\tOrdinal0 [0x0019D7F4+1103860]\n\tOrdinal0 [0x001ADAE2+1170146]\n\tOrdinal0 [0x0019D5C6+1103302]\n\tOrdinal0 [0x001777E0+948192]\n\tOrdinal0 [0x001786E6+952038]\n\tGetHandleVerifier [0x00550CB2+2738370]\n\tGetHandleVerifier [0x005421B8+2678216]\n\tGetHandleVerifier [0x003317AA+512954]\n\tGetHandleVerifier [0x00330856+509030]\n\tOrdinal0 [0x0024743B+1799227]\n\tOrdinal0 [0x0024BB68+1817448]\n\tOrdinal0 [0x0024BC55+1817685]\n\tOrdinal0 [0x00255230+1856048]\n\tBaseThreadInitThunk [0x778CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77E37A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77E37A6E+238]\n\t(No symbol) [0x00000000]\n"
     ]
    }
   ],
   "source": [
    "# scraping Description\n",
    "Description=[]\n",
    "for i in driver.find_elements(By.XPATH,\"//*[@id='post-1953']/div/div/p[1]/text()\"):\n",
    "    Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8c03441",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3284/4008797973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# creating the dataframe from the scraped data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSelenium\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Exception_Name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mDescription\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mSelenium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data\n",
    "Selenium = pd.DataFrame({'Exception_Name':Name,'Description':Description})\n",
    "Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8111b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b8be78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad454baa",
   "metadata": {},
   "source": [
    "# Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b77d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = (\"https://statisticstimes.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd3ba92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a2be086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on India\n",
    "driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[1]/div\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63341abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank\n",
    "Rank=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1a0ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping State\n",
    "State=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4293332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP at current price (19-20)\n",
    "GSDP1=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8b9692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP at current price (18-19)\n",
    "GSDP2=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a02f6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Share (18-19)\n",
    "Share=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "693a5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GDP $ billion\n",
    "GDP_billion=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7976f36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP at current price (19-20)  \\\n",
       "0     1                Maharashtra                             -   \n",
       "1     2                 Tamil Nadu                     1,845,853   \n",
       "2     3              Uttar Pradesh                     1,687,818   \n",
       "3     4                    Gujarat                             -   \n",
       "4     5                  Karnataka                     1,631,977   \n",
       "..  ...                        ...                           ...   \n",
       "61   29                     Sikkim                        28,391   \n",
       "62   30                   Nagaland                             -   \n",
       "63   31          Arunachal Pradesh                             -   \n",
       "64   32                    Mizoram                        24,424   \n",
       "65   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP at current price (18-19) Share (18-19) GDP($ billion)  \n",
       "0                      2,632,792        13.94%        399.921  \n",
       "1                      1,630,208         8.63%        247.629  \n",
       "2                      1,584,764         8.39%        240.726  \n",
       "3                      1,502,899         7.96%        228.290  \n",
       "4                      1,493,127         7.91%        226.806  \n",
       "..                           ...           ...            ...  \n",
       "61                        25,141         0.15%         17,060  \n",
       "62                        24,534         0.15%              -  \n",
       "63                        22,488         0.13%              -  \n",
       "64                        20,947         0.13%         17,797  \n",
       "65                             -             -              -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share (18-19)'] = Share\n",
    "GDP['GDP($ billion)'] = GDP_billion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6081c2",
   "metadata": {},
   "source": [
    "# Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e4f3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the web driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "# getting the webpage of mentioned url\n",
    "url = (\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b1b1a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting explore button and clicking on it\n",
    "explore = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d31dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting trending option\n",
    "trend_url = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a\")\n",
    "urls = trend_url.get_attribute('href')\n",
    "driver.get(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a4a0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching urls for each repository\n",
    "URL=[]\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class='h3 lh-condensed']//a\")[0:10]\n",
    "for i in repository:\n",
    "    URL.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd4086f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Repository title data\n",
    "repository_title=[]\n",
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7cf01415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data from all repository page\n",
    "for i in URL:\n",
    "    driver.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c68cf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Repository Description data \n",
    "Description=[]\n",
    "try:\n",
    "    desc = driver.find_element(By.XPATH,\"//p[@class='f4 mt-3']\")\n",
    "    Description.append(desc.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b73129e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Contributors Count data\n",
    "Contributors=[]\n",
    "try:\n",
    "    contributor = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "    Contributors.append(contributor.text.replace('Contributors',''))\n",
    "except NoSuchElementException:\n",
    "    Contributors.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2224d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Languages used data\n",
    "lang=[]\n",
    "Language=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//ul[@class= 'list-style-none']//li//span[1]\"):\n",
    "        lang.append(i.text)\n",
    "    Language.append(lang)\n",
    "except NoSuchElementException:\n",
    "    Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "19672adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5048/2881067399.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mGithub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Repository Title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepository_title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Repository Description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDescription\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Contributors Count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContributors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mGithub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Language Used'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (1) does not match length of index (25)"
     ]
    }
   ],
   "source": [
    "# Data Framing\n",
    "Github = pd.DataFrame({})\n",
    "Github['Repository Title'] = repository_title\n",
    "Github['Repository Description'] = Description\n",
    "Github['Contributors Count'] = Contributors\n",
    "Github['Language Used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd67df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7067035",
   "metadata": {},
   "source": [
    "# Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "137b05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.billboard.com/'\n",
    "driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b11dd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "top100_button = driver.find_element(By.XPATH,\"//*[@id='main-wrapper']/header/div[2]/div/nav/ul/li[1]/a\")\n",
    "top100_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e9b83d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having song name\n",
    "name_song=[]\n",
    "name =driver.find_element(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "#to remove extra data other than output we required\n",
    "name_song.append(name.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "056d7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having artist name\n",
    "artist_name=[]\n",
    "artist = driver.find_element(By.XPATH,\"//*[@id='post-1479786']/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/span\")\n",
    "#to remove extra data other than output we required\n",
    "artist_name.append(artist.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a26dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having last week rank\n",
    "last_week=[]\n",
    "last = driver.find_element(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[4]/span\")\n",
    "#to remove extra data other than output we required\n",
    "last_week.append(last.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf04af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having last peak rank\n",
    "peak_rank=[]\n",
    "peak=driver.find_element(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]/span\")\n",
    "peak_rank.append(peak.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "27fbb017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having last week rank\n",
    "weeks_board=[]\n",
    "week= driver.find_element(By.XPATH,\"/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[6]/span\")\n",
    "weeks_board.append(week.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36bdaa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Song_name   Artist_name Last_week_rank Peak_rank Weeks_on_board\n",
       "0  As It Was  Harry Styles              1         1             23"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of hot 100 from https://www.billboard.com/\n",
    "Hot_100 = pd.DataFrame({})\n",
    "Hot_100['Song_name']= name_song\n",
    "Hot_100['Artist_name'] = artist_name\n",
    "Hot_100['Last_week_rank'] = last_week \n",
    "Hot_100['Peak_rank'] = peak_rank\n",
    "Hot_100['Weeks_on_board'] = weeks_board\n",
    "Hot_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "48a5ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea6a77",
   "metadata": {},
   "source": [
    "# Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "35dfc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7594d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Openings the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dba99184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enterning designation and location as requried in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7da95720",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c6d2b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_requried=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e1a6f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')    #Relative path\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eb51ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job location from the given page  \n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    job_location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8eef7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping company name from the given page       \n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee8110df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping exp requried from the given page    \n",
    "exp_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    experience_requried.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "749fd7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_requried))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c559c223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>exp_requried</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Analyst &amp; AI Lead - Data Science</td>\n",
       "      <td>New Delhi, Faridabad, Gurgaon/Gurugram, Delhi ...</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Analyst - Data Science - IIT/NIT/IIM/XL...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Analyst &amp; AI Lead - Data Science</td>\n",
       "      <td>Faridabad, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Trainee- Data Science</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Survik Software Pvt Ltd</td>\n",
       "      <td>9-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For AVP |Data Science and Business Anal...</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Citicorp Finance</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning/Technical Analyst/Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bartleby Technologies</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data Science Analyst</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>TransUnion</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                        Senior Analyst-Data Science   \n",
       "1            Senior Analyst & AI Lead - Data Science   \n",
       "2  Senior Analyst - Data Science - IIT/NIT/IIM/XL...   \n",
       "3            Senior Analyst & AI Lead - Data Science   \n",
       "4                        Senior Analyst-Data Science   \n",
       "5                        Senior Analyst-Data Science   \n",
       "6                              Trainee- Data Science   \n",
       "7  Hiring For AVP |Data Science and Business Anal...   \n",
       "8    Machine Learning/Technical Analyst/Data Science   \n",
       "9                            Sr Data Science Analyst   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1  New Delhi, Faridabad, Gurgaon/Gurugram, Delhi ...   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3           Faridabad, Gurgaon/Gurugram, Delhi / NCR   \n",
       "4                                   Gurgaon/Gurugram   \n",
       "5                                   Gurgaon/Gurugram   \n",
       "6                                               Pune   \n",
       "7                          Pune, Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                            Chennai   \n",
       "\n",
       "                company_name exp_requried  \n",
       "0                  Accenture      5-8 Yrs  \n",
       "1  Huquo Consulting Pvt. Ltd      2-7 Yrs  \n",
       "2  Huquo Consulting Pvt. Ltd      2-5 Yrs  \n",
       "3  Huquo Consulting Pvt. Ltd      2-7 Yrs  \n",
       "4                  Accenture      5-8 Yrs  \n",
       "5                  Accenture      5-8 Yrs  \n",
       "6    Survik Software Pvt Ltd     9-13 Yrs  \n",
       "7           Citicorp Finance     5-10 Yrs  \n",
       "8      Bartleby Technologies     7-10 Yrs  \n",
       "9                 TransUnion      2-5 Yrs  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the database from above data\n",
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'exp_requried':experience_requried})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9ecdc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7574083c",
   "metadata": {},
   "source": [
    "# Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b15cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7209d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "rank =driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "#to remove extra data other than output we required\n",
    "Rank= []\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "BOOK_NAME = []\n",
    "for i in Book_Name[1: :5]:\n",
    "    BOOK_NAME.append(i)\n",
    "\n",
    "Auther_Name = []\n",
    "for i in Rank[2: :5]:\n",
    "    Auther_Name.append(i)\n",
    "\n",
    "Volume_sold = []\n",
    "for i in Rank[3: :5]:\n",
    "    Volume_sold.append(i)\n",
    "\n",
    "Publisher = []\n",
    "for i in Rank[4: :5]:\n",
    "    Publisher.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c6a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "genre =driver.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "#to remove extra data other than output we required\n",
    "Genre = []\n",
    "for i in genre:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cea0eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOOK_NAME</th>\n",
       "      <th>Auther_Name</th>\n",
       "      <th>Volume_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            BOOK_NAME       Auther_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume_sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of hot 100 from https://www.billboard.com/\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['BOOK_NAME']= BOOK_NAME\n",
    "Novels['Auther_Name'] = Auther_Name\n",
    "Novels['Volume_sold'] = Volume_sold \n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre \n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0aefc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c5a6e",
   "metadata": {},
   "source": [
    "# Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "769bf434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30e1fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Name\n",
    "name = driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']\")\n",
    "#to remove extra data other than output we required\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33ef388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having year span\n",
    "year = driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "#to remove extra data other than output we required\n",
    "Year=[]\n",
    "for i in year:\n",
    "    Year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f5af57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Genre\n",
    "genre = driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "#to remove extra data other than output we required\n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f933b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having run time\n",
    "run = driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "#to remove extra data other than output we required\n",
    "Run_Time=[]\n",
    "for i in run:\n",
    "    Run_Time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3550082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having ratings\n",
    "ratings = driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']\")\n",
    "#to remove extra data other than output we required\n",
    "Ratings=[]\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "125e97d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having voting\n",
    "voting =driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "#to remove extra data other than output we required\n",
    "Voting=[]\n",
    "for i in voting:\n",
    "    Voting.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9391bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,048,909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016– )</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,144,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>968,153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>288,795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>248,375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005–2020)</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>194,764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>236,388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              NAME    Year Span  \\\n",
       "0                   1. Game of Thrones (2011–2019)  (2011–2019)   \n",
       "1                      2. Stranger Things (2016– )     (2016– )   \n",
       "2                  3. The Walking Dead (2010–2022)  (2010–2022)   \n",
       "3                    4. 13 Reasons Why (2017–2020)  (2017–2020)   \n",
       "4                           5. The 100 (2014–2020)  (2014–2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013–2017)  (2013–2017)   \n",
       "96  97. A Series of Unfortunate Events (2017–2019)  (2017–2019)   \n",
       "97                  98. Criminal Minds (2005–2020)  (2005–2020)   \n",
       "98           99. Scream: The TV Series (2015–2019)  (2015–2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run Time Ratings     Voting  \n",
       "0   Action, Adventure, Drama   57 min     9.2  2,048,909  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7  1,144,963  \n",
       "2    Drama, Horror, Thriller   44 min     8.1    968,153  \n",
       "3   Drama, Mystery, Thriller   60 min     7.5    288,795  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    248,375  \n",
       "..                       ...      ...     ...        ...  \n",
       "95                     Drama   42 min     7.4     49,552  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     60,557  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    194,764  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     41,021  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    236,388  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of tv series 100 from imdb.com\n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['NAME']= Name\n",
    "TV_Series['Year Span'] = Year\n",
    "TV_Series['Genre'] = Genre \n",
    "TV_Series['Run Time'] = Run_Time\n",
    "TV_Series['Ratings'] = Ratings \n",
    "TV_Series['Voting'] = Voting \n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d738c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde289a",
   "metadata": {},
   "source": [
    "# Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f870f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dedd3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "dataset_button =driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "dataset_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e7dd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "name = driver.find_elements(By.XPATH,\"//td[@valign='top']//a\")\n",
    "#to remove extra data other than output we required\n",
    "Dataset_Name=[]\n",
    "for i in name:\n",
    "    Dataset_Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c9e774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "datat = driver.find_elements(By.XPATH,\"//td[@valign='top']//p\")\n",
    "#to remove extra data other than output we required\n",
    "Data_type=[]\n",
    "for i in datat:\n",
    "    Data_type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fa253c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "task = driver.find_elements(By.XPATH,\"//td[@valign='top']//p\")\n",
    "#to remove extra data other than output we required\n",
    "Task=[]\n",
    "for i in task:\n",
    "    Task.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f757e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (4378) does not match length of index (1287)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3284/3413436497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mML_REPOSITORIES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mML_REPOSITORIES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Dataset_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mDataset_Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mML_REPOSITORIES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data_Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mML_REPOSITORIES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Task'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTASK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mML_REPOSITORIES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (4378) does not match length of index (1287)"
     ]
    }
   ],
   "source": [
    "# Make data frame of Datasets from UCI machine learning repositories from Url = https://archive.ics.uci.edu/\n",
    "ML_REPOSITORIES = pd.DataFrame({})\n",
    "ML_REPOSITORIES['Dataset_name']= Dataset_Name\n",
    "ML_REPOSITORIES['Data_Type'] = Data_type\n",
    "ML_REPOSITORIES['Task'] = TASK \n",
    "ML_REPOSITORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493b390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
